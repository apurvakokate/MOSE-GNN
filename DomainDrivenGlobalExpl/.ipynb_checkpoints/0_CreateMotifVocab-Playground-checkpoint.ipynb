{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4539703-668c-4f32-9460-4f409f6ec112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv(\"BBBP.csv\")\n",
    "\n",
    "# # Rename the column CT_TOX to clintox\n",
    "# df.rename(columns={'p_np': 'BBBP'}, inplace=True)\n",
    "\n",
    "# # Split the data into training (80%) and temp (20%)\n",
    "# train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['BBBP'], random_state=42)\n",
    "\n",
    "# # Split the temp data into validation (10%) and test (10%)\n",
    "# valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['BBBP'], random_state=42)\n",
    "\n",
    "# # Add the group column\n",
    "# train_df['group'] = 'training'\n",
    "# valid_df['group'] = 'valid'\n",
    "# test_df['group'] = 'test'\n",
    "\n",
    "# # Concatenate the dataframes back together\n",
    "# final_df = pd.concat([train_df, valid_df, test_df])\n",
    "\n",
    "# # Save the final dataframe to a new CSV\n",
    "# final_df.to_csv(\"BBBP_with_groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fd8fab-2f99-42ab-bb72-c4cda7770c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'hERG' # Choose from 'Mutagenicity', 'hERG', 'BBBP', 'clintox'\n",
    "date_tag = '0930'\n",
    "least_count = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195aa383-304f-4297-8738-0036e9448224",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5646a6fb-f9fa-43e0-9612-7d71754c1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "# Check if gpu is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dfff0b-58b0-418b-a6fd-473717f3d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import MolDataset\n",
    "training_data = MolDataset(root=\".\", split='training',csv_file=f\"{dataset_name}.csv\")\n",
    "validation_data = MolDataset(root=\".\", split='valid',csv_file=f\"{dataset_name}.csv\")\n",
    "test_data = MolDataset(root=\".\", split='test',csv_file=f\"{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285466e7-495e-4131-8dc6-3e80b5b9cd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7900, 26, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.num_classes, len(training_data), training_data.num_node_features, training_data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aed500-417a-44e5-9b64-6d7092a098c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 987, 26, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.num_classes, len(validation_data), validation_data.num_node_features, validation_data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d93819-69b8-4aa4-8da8-6c727753eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 988, 26, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.num_classes, len(test_data), test_data.num_node_features, test_data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56cae3c-7fec-47e6-86ef-4d017d0983c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def remove_bad_mols(dataset):\n",
    "    indices_to_remove = np.ones(len(dataset), dtype=bool)\n",
    "    for i,data in enumerate(dataset):\n",
    "        if data is None: \n",
    "            indices_to_remove[i] = False\n",
    "        elif data.num_nodes == 0:\n",
    "            print(f\"Skipping molecule {data['smiles']} since it \"\n",
    "                      f\"resulted in zero atoms\")\n",
    "            indices_to_remove[i] = False\n",
    "\n",
    "    return dataset[indices_to_remove]\n",
    "training_data = remove_bad_mols(training_data)\n",
    "validation_data = remove_bad_mols(validation_data)\n",
    "test_data = remove_bad_mols(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c595aaaf-f4f7-4df2-9ee7-f396864ac4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7900, 26, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.num_classes, len(training_data), training_data.num_node_features, training_data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782c74d5-15fa-40f1-9796-8624147da394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 987, 26, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.num_classes, len(validation_data), validation_data.num_node_features, validation_data.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776ea674-56d8-4055-abc1-8cfed2518095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 988, 26, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.num_classes, len(test_data), test_data.num_node_features, test_data.num_edge_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86091e54-3251-47b9-956f-54e666ab0bc7",
   "metadata": {},
   "source": [
    "# Create Motif Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74c77a7-3cf5-4200-9b1c-65aa74192fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "def mol_with_atom_index(mol):\n",
    "    '''\n",
    "    Add Atom indices to a Rdkit molecule\n",
    "    Input: Rdkit molecule object\n",
    "    '''\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom.SetAtomMapNum(atom.GetIdx())\n",
    "    return mol\n",
    "\n",
    "def get_mol(smiles, set_atom_index = True):\n",
    "    '''\n",
    "    Coverts a Smiles String to a Rdkit Molecule\n",
    "    Input: Smiles representation of molecule, flag to recreate atom indexs \n",
    "    CCCC\n",
    "    C1C2C3C4\n",
    "    '''\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    Chem.Kekulize(mol)\n",
    "    # Check if smiles has index using Rdkit function\n",
    "    if set_atom_index:\n",
    "        return mol_with_atom_index(mol)\n",
    "    else:\n",
    "        return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86804dbf-31fe-4de6-870c-57f9c3cb7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "def atom_counts(smiles):\n",
    "    # Parse the SMILES string to a molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    assert(mol.GetNumAtoms() > 0)\n",
    "    \n",
    "    # Extract atoms from the molecule\n",
    "    atoms = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
    "    \n",
    "    # Count occurrences of each atom\n",
    "    atom_count = Counter(atoms)\n",
    "    \n",
    "    # Sort atoms alphabetically and create the result string\n",
    "    sorted_atoms = sorted(atom_count.items())\n",
    "    result = ''.join(f\"{atom}{count}\" for atom, count in sorted_atoms)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class MotifDictionary:\n",
    "    def __init__(self):\n",
    "        self.data = defaultdict(lambda: defaultdict())\n",
    "        self.test_data = defaultdict(lambda: defaultdict())\n",
    "        self.motifs_length = defaultdict()\n",
    "        self.motifs_class = defaultdict(dict)\n",
    "        self.test_motifs_length = defaultdict()\n",
    "\n",
    "    def add_entry(self, graph_str, motif_str, nodes, class_id):\n",
    "        '''\n",
    "        Maps a Graph String and nodes within the graph to a Motif String\n",
    "        '''\n",
    "        # motif_str = atom_counts(motif_str)\n",
    "        for element in nodes:\n",
    "            if element is not None:\n",
    "                self.data[graph_str][element]= motif_str \n",
    "        self.motifs_class[motif_str][graph_str] = class_id\n",
    "        self.motifs_length[motif_str]= len(nodes) - nodes.count(None)\n",
    "        \n",
    "    def add_entry_test(self, graph_str, motif_str, nodes, class_id):\n",
    "        '''\n",
    "        Maps a Graph String and nodes within the graph to a Motif String\n",
    "        '''\n",
    "        # motif_str = atom_counts(motif_str)\n",
    "        for element in nodes:\n",
    "            if element is not None:\n",
    "                \n",
    "                self.test_data[graph_str][element]= motif_str \n",
    "                \n",
    "        self.test_motifs_length[motif_str]= len(nodes) - nodes.count(None)\n",
    "\n",
    "    def query_by_graph(self, graph_str):\n",
    "        '''\n",
    "        Returns Nodes to Motif_String map\n",
    "        '''\n",
    "        return self.data.get(graph_str, {})\n",
    "    \n",
    "    def query_by_test_graph(self, graph_str):\n",
    "        '''\n",
    "        Returns Nodes to Motif_String map\n",
    "        '''\n",
    "        return self.test_data.get(graph_str, {})\n",
    "    \n",
    "    def remove_motifs(self, list_of_motifs_to_remove):\n",
    "        '''\n",
    "        Removes less frequent motifs\n",
    "        '''\n",
    "        for key in list_of_motifs_to_remove:\n",
    "            self.motifs_length.pop(key)\n",
    "            self.motifs_class.pop(key)\n",
    "\n",
    "    def get_all_unique_motif(self):\n",
    "        '''\n",
    "        All unique motifs\n",
    "        '''\n",
    "        return list(self.motifs_length.keys())\n",
    "    \n",
    "    def get_motif_lengths(self):\n",
    "        return self.motifs_length\n",
    "    \n",
    "    def get_test_motif_lengths(self):\n",
    "        return self.test_motifs_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cbcfd2-0634-45fa-bb77-de44a514017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lookup = MotifDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953950d8-3a5d-4117-b1c5-f63f28b98284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from rdkit import Chem\n",
    "from rBRICS_public import *\n",
    "from rdkit.Chem import BRICS\n",
    "# from rdkit.Chem.BRICS import FindBRICSBonds, BreakBRICSBonds\n",
    "\n",
    "def canonicalize_fragment(fragment):\n",
    "    sorted_atoms = sorted(fragment.GetAtoms(), key=lambda atom: atom.GetSymbol())\n",
    "    return Chem.MolToSmiles(sorted_atoms, isomericSmiles=True)\n",
    "\n",
    "def process_molecule(smiles_string, original_mol=True):\n",
    "    \"\"\"Creates an RDKit molecule and preserves atom indices if not the original molecule.\"\"\"\n",
    "    if original_mol:\n",
    "        molecule = get_mol(smiles_string)\n",
    "    else:\n",
    "        molecule = get_mol(smiles_string, set_atom_index=False)\n",
    "    Chem.SanitizeMol(molecule)\n",
    "    return molecule\n",
    "\n",
    "def fragment_molecule(molecule):\n",
    "    \"\"\"Break the molecule into fragments using BRICS.\"\"\"\n",
    "    pbonds = list(FindrBRICSBonds(molecule))\n",
    "    ppieces3 = BreakrBRICSBonds(molecule, pbonds)\n",
    "    return Chem.GetMolFrags(ppieces3, asMols=True)\n",
    "\n",
    "def brics_decomp(mol):\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    if n_atoms == 1:\n",
    "        return [[0]], []\n",
    "\n",
    "    cliques = []\n",
    "    breaks = []\n",
    "    for bond in mol.GetBonds():\n",
    "        a1 = bond.GetBeginAtom().GetIdx()\n",
    "        a2 = bond.GetEndAtom().GetIdx()\n",
    "        cliques.append([a1, a2])\n",
    "\n",
    "    res = list(BRICS.FindBRICSBonds(mol))\n",
    "    if len(res) == 0:\n",
    "        return [list(range(n_atoms))], []\n",
    "    else:\n",
    "        for bond in res:\n",
    "            if [bond[0][0], bond[0][1]] in cliques:\n",
    "                cliques.remove([bond[0][0], bond[0][1]])\n",
    "            else:\n",
    "                cliques.remove([bond[0][1], bond[0][0]])\n",
    "            cliques.append([bond[0][0]])\n",
    "            cliques.append([bond[0][1]])\n",
    "\n",
    "    # break bonds between rings and non-ring atoms\n",
    "    for c in cliques:\n",
    "        if len(c) > 1:\n",
    "            if mol.GetAtomWithIdx(c[0]).IsInRing() and not mol.GetAtomWithIdx(c[1]).IsInRing():\n",
    "                cliques.remove(c)\n",
    "                cliques.append([c[1]])\n",
    "                breaks.append(c)\n",
    "            if mol.GetAtomWithIdx(c[1]).IsInRing() and not mol.GetAtomWithIdx(c[0]).IsInRing():\n",
    "                cliques.remove(c)\n",
    "                cliques.append([c[0]])\n",
    "                breaks.append(c)\n",
    "\n",
    "    # select atoms at intersections as motif\n",
    "    for atom in mol.GetAtoms():\n",
    "        if len(atom.GetNeighbors()) > 2 and not atom.IsInRing():\n",
    "            cliques.append([atom.GetIdx()])\n",
    "            for nei in atom.GetNeighbors():\n",
    "                if [nei.GetIdx(), atom.GetIdx()] in cliques:\n",
    "                    cliques.remove([nei.GetIdx(), atom.GetIdx()])\n",
    "                    breaks.append([nei.GetIdx(), atom.GetIdx()])\n",
    "                elif [atom.GetIdx(), nei.GetIdx()] in cliques:\n",
    "                    cliques.remove([atom.GetIdx(), nei.GetIdx()])\n",
    "                    breaks.append([atom.GetIdx(), nei.GetIdx()])\n",
    "                cliques.append([nei.GetIdx()])\n",
    "\n",
    "    # merge cliques\n",
    "    for c in range(len(cliques) - 1):\n",
    "        if c >= len(cliques):\n",
    "            break\n",
    "        for k in range(c + 1, len(cliques)):\n",
    "            if k >= len(cliques):\n",
    "                break\n",
    "            if len(set(cliques[c]) & set(cliques[k])) > 0:\n",
    "                cliques[c] = list(set(cliques[c]) | set(cliques[k]))\n",
    "                cliques[k] = []\n",
    "        cliques = [c for c in cliques if len(c) > 0]\n",
    "    cliques = [c for c in cliques if len(c) > 0]\n",
    "\n",
    "    # edges\n",
    "    edges = []\n",
    "    for bond in res:\n",
    "        for c in range(len(cliques)):\n",
    "            if bond[0][0] in cliques[c]:\n",
    "                c1 = c\n",
    "            if bond[0][1] in cliques[c]:\n",
    "                c2 = c\n",
    "        edges.append((c1, c2))\n",
    "    for bond in breaks:\n",
    "        for c in range(len(cliques)):\n",
    "            if bond[0] in cliques[c]:\n",
    "                c1 = c\n",
    "            if bond[1] in cliques[c]:\n",
    "                c2 = c\n",
    "        edges.append((c1, c2))\n",
    "\n",
    "    return cliques, edges\n",
    "\n",
    "def extract_clique_fragments(mol, cliques):\n",
    "    \n",
    "    fragments = []\n",
    "    \n",
    "    # Iterate over each clique\n",
    "    for clique in cliques:\n",
    "        # Create a new editable molecule for the fragment\n",
    "        editable_mol = Chem.RWMol()\n",
    "\n",
    "        # Mapping of original atom indices to new indices in the fragment\n",
    "        atom_map = {}\n",
    "\n",
    "        # Add atoms from the clique to the new molecule\n",
    "        for atom_idx in clique:\n",
    "            atom = mol.GetAtomWithIdx(atom_idx)\n",
    "            new_idx = editable_mol.AddAtom(atom)\n",
    "            atom_map[atom_idx] = new_idx  # Map original index to new fragment index\n",
    "\n",
    "        # Add bonds between the atoms in the clique\n",
    "        added_bonds = set()  # Track bonds that have been added to avoid duplicates\n",
    "        for atom_idx in clique:\n",
    "            for neighbor in mol.GetAtomWithIdx(atom_idx).GetNeighbors():\n",
    "                neighbor_idx = neighbor.GetIdx()\n",
    "                if neighbor_idx in clique:\n",
    "                    # Create a sorted tuple of atom indices to avoid duplicate bonds\n",
    "                    bond_tuple = tuple(sorted([atom_idx, neighbor_idx]))\n",
    "                    if bond_tuple not in added_bonds:\n",
    "                        # Add the bond between the atoms in the clique\n",
    "                        bond = mol.GetBondBetweenAtoms(atom_idx, neighbor_idx)\n",
    "                        if bond:\n",
    "                            editable_mol.AddBond(atom_map[atom_idx], atom_map[neighbor_idx], bond.GetBondType())\n",
    "                            added_bonds.add(bond_tuple)  # Mark the bond as added\n",
    "\n",
    "        # Sanitize and append the fragment molecule\n",
    "        fragment = editable_mol.GetMol()\n",
    "        # Disable Kekulization and sanitize the molecule with Kekulization turned off\n",
    "        Chem.SanitizeMol(fragment, Chem.SanitizeFlags.SANITIZE_ALL ^ Chem.SanitizeFlags.SANITIZE_KEKULIZE)\n",
    "\n",
    "        fragments.append(fragment)\n",
    "    \n",
    "    return fragments\n",
    "\n",
    "\n",
    "def handle_fragment(fragment, molecule_smiles, data, is_test=False):\n",
    "    \"\"\"Handle a fragment by checking if it can be further broken down or adding it to the lookup.\"\"\"\n",
    "    fbonds = list(FindrBRICSBonds(fragment))\n",
    "    if len(fbonds) == 0:\n",
    "        atom_nums = [atom.GetAtomMapNum() if atom.GetAtomicNum() != 0 else None for atom in fragment.GetAtoms()]\n",
    "        [a.SetAtomMapNum(0) for a in fragment.GetAtoms()]  # Remove atom map for unique motif\n",
    "        fragment_smiles = Chem.MolToSmiles(fragment, isomericSmiles=False, canonical=True)\n",
    "        if is_test:\n",
    "            lookup.add_entry_test(molecule_smiles, fragment_smiles, atom_nums, data.y.item())\n",
    "        else:\n",
    "            lookup.add_entry(molecule_smiles, fragment_smiles, atom_nums, data.y.item())\n",
    "    else:\n",
    "        fragment_smiles = Chem.MolToSmiles(fragment)\n",
    "        return fragment_smiles\n",
    "\n",
    "def process_dataset(dataset, is_test=False):\n",
    "    \"\"\"Processes a dataset (train/test) and fragments each molecule.\"\"\"\n",
    "    \n",
    "    [extract_clique_fragments(Chem.MolFromSmiles(i.smiles), brics_decomp(Chem.MolFromSmiles(i.smiles))[0]) for _, i in df.iterrows()]\n",
    "    for i, data in enumerate(dataset):\n",
    "        molecule_smiles = data[\"smiles\"]\n",
    "        # to_process = [molecule_smiles]\n",
    "        original_mol = True\n",
    "        \n",
    "        # while to_process:\n",
    "        # smiles_string = to_process.pop()\n",
    "        molecule = process_molecule(molecule_smiles, original_mol)\n",
    "            # original_mol = False\n",
    "            \n",
    "            # all_fragments = fragment_molecule(molecule)\n",
    "            \n",
    "        mgssl_fragments_cliques, edges_to_break = brics_decomp(molecule)\n",
    "        all_fragments = extract_clique_fragments(molecule, mgssl_fragments_cliques)\n",
    "            \n",
    "#             input(all_fragments)\n",
    "            \n",
    "#             input(mgssl_fragments_cliques)\n",
    "            \n",
    "#             input(edges)\n",
    "            \n",
    "            \n",
    "        for fragment in all_fragments:\n",
    "            atom_nums = [atom.GetAtomMapNum() if atom.GetAtomicNum() != 0 else None for atom in fragment.GetAtoms()]\n",
    "            for a in fragment.GetAtoms():  # Remove atom map for unique motif\n",
    "                a.SetAtomMapNum(0) \n",
    "            fragment_smiles = Chem.MolToSmiles(fragment, isomericSmiles=False, canonical=True)\n",
    "            if is_test:\n",
    "                lookup.add_entry_test(molecule_smiles, fragment_smiles, atom_nums, data.y.item())\n",
    "            else:\n",
    "                lookup.add_entry(molecule_smiles, fragment_smiles, atom_nums, data.y.item())\n",
    "            # fragment_smiles = handle_fragment(fragment, molecule_smiles, data, is_test)\n",
    "            # if fragment_smiles:\n",
    "            #     to_process.append(fragment_smiles)\n",
    "                \n",
    "# Process training and validation datasets\n",
    "process_dataset(training_data + validation_data)\n",
    "\n",
    "# Process test dataset\n",
    "process_dataset(test_data, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a31186-1c7b-4896-a25b-87484519ec0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(lookup.get_all_unique_motif())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9519e-d480-4014-9640-af52b681848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lookup = dict(lookup.data)\n",
    "test_data_lookup = dict(lookup.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82bda6e-eb96-4308-bcf7-74d9677f2cc2",
   "metadata": {},
   "source": [
    "## Unit Testing. Check if number of motifs in each graph match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f35ffb-1668-4528-b0e1-c032f95f3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Count all motifs in each graph / divided by size of motif\n",
    "total_motifs = 0\n",
    "total_motifs_test = 0\n",
    "for smiles, node_map in data_lookup.items():\n",
    "    \n",
    "    for node_idx, motif in node_map.items():\n",
    "        \n",
    "        length_of_motif = lookup.motifs_length[motif] \n",
    "        total_motifs += 1/length_of_motif\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the nested dictionary into a list of strings\n",
    "all_values = [value for inner_dict in data_lookup.values() for value in inner_dict.values()]\n",
    "all_values_test = [value for inner_dict in test_data_lookup.values() for value in inner_dict.values()]\n",
    "\n",
    "# Count occurrences of each unique value\n",
    "value_counts = Counter(all_values)\n",
    "value_counts_test = Counter(all_values_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c29b3-8607-4213-a35d-77c39227c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_motif_count = 0\n",
    "motif_count_list = {}\n",
    "for motifs, length in lookup.motifs_length.items():\n",
    "    verify_motif_count += value_counts[motifs]/length\n",
    "    motif_count_list[motifs] = value_counts[motifs]/length\n",
    "motif_count_list_test = {}\n",
    "for motifs, length in lookup.test_motifs_length.items():\n",
    "    motif_count_list_test[motifs] = value_counts_test[motifs]/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b066c-0bf4-43e1-8727-0ecc89e8fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(round(total_motifs) == round(verify_motif_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ef3c3-42cf-49f9-a045-2256116f370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(total_motifs), round(verify_motif_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ae2cb-f404-4ea2-9fb7-a6b5474a4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k,v in motif_count_list.items() if v < least_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f31499-eacb-4a05-a999-5e0f2d5b4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k,v in motif_count_list_test.items() if v < least_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f17cc-1b26-4ecd-a8e3-9cb9fcfd16f4",
   "metadata": {},
   "source": [
    "# Filtering motifs that are same acrooss bothe classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d3e1e-06c8-4286-bc84-eca20bbd010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motif_list = list(lookup.get_all_unique_motif())\n",
    "# graph_to_motifs = defaultdict(set)\n",
    "# data_lookup = dict(lookup.data)\n",
    "# for graph_str, value in data_lookup.items():\n",
    "#     for node_id, m_str in data_lookup[graph_str].items():\n",
    "#         if value_counts[m_str] > least_count:\n",
    "#             try:\n",
    "#                 data_lookup[graph_str][node_id] = (m_str, motif_list.index(m_str))\n",
    "#                 # motif_occurence.append(m_str)\n",
    "#                 graph_to_motifs[graph_str].add(motif_list.index(m_str))\n",
    "#             except ValueError as e:\n",
    "#                 input(m_str)\n",
    "#                 # Support for future developement in freezing % motifs\n",
    "#                 data_lookup[graph_str][node_id] = (m_str, None)\n",
    "#         else:\n",
    "#             data_lookup[graph_str][node_id] = (m_str, None)\n",
    "motif_list = list(lookup.get_all_unique_motif())\n",
    "graph_to_motifs = defaultdict(set)\n",
    "data_lookup = dict(lookup.data)\n",
    "\n",
    "list_of_motif_to_remove = set()\n",
    "for graph_str, value in data_lookup.items():\n",
    "    for node_id, m_str in data_lookup[graph_str].items():\n",
    "        if motif_count_list[m_str] <= least_count:\n",
    "            list_of_motif_to_remove.add(m_str)\n",
    "            \n",
    "lookup.remove_motifs(list(list_of_motif_to_remove))\n",
    "            \n",
    "            \n",
    "motif_list = list(lookup.get_all_unique_motif())\n",
    "graph_to_motifs = defaultdict(set)\n",
    "data_lookup = dict(lookup.data)\n",
    "for graph_str, value in data_lookup.items():\n",
    "    for node_id, m_str in data_lookup[graph_str].items():\n",
    "        if motif_count_list[m_str] > least_count:\n",
    "            data_lookup[graph_str][node_id] = (m_str, motif_list.index(m_str))\n",
    "            graph_to_motifs[graph_str].add(motif_list.index(m_str))\n",
    "            \n",
    "        else:\n",
    "            data_lookup[graph_str][node_id] = (m_str, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b64457-b7d3-4c72-9c1b-e59b05624fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph_to_motifs = defaultdict(set)\n",
    "for graph_str, value in test_data_lookup.items():\n",
    "    for node_id, m_str in test_data_lookup[graph_str].items():\n",
    "        try:\n",
    "            test_data_lookup[graph_str][node_id] = (m_str, motif_list.index(m_str))\n",
    "            # motif_occurence.append(m_str)\n",
    "            test_graph_to_motifs[graph_str].add(motif_list.index(m_str))\n",
    "        except ValueError as e:\n",
    "            # input(m_str)\n",
    "            # Support for future developement in freezing % motifs\n",
    "            test_data_lookup[graph_str][node_id] = (m_str, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3322fdc-16be-4cb0-acf3-8e05d2d48f87",
   "metadata": {},
   "source": [
    "# Saved lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef5851-73ec-4975-8508-863b8dc9f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_lookup = dict(lookup.data)\n",
    "# Open a file in write mode\n",
    "with open(f'dictionary/{dataset_name}_graph_lookup_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(data_lookup, file)\n",
    "\n",
    "with open(f'dictionary/{dataset_name}_motif_list_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(list(lookup.get_all_unique_motif()), file)\n",
    "    \n",
    "with open(f'dictionary/{dataset_name}_motif_length_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(lookup.get_motif_lengths(), file)\n",
    "    \n",
    "with open(f'dictionary/{dataset_name}_motif_counts_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(value_counts, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e34af-1991-4496-8a52-8754e2191518",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'dictionary/{dataset_name}_motif_class_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(lookup.motifs_class, file)\n",
    "    \n",
    "with open(f'dictionary/{dataset_name}_graph_motifidx_{date_tag}.pickle', 'wb') as file:\n",
    "    pickle.dump(graph_to_motifs, file)\n",
    "    \n",
    "with open(f'dictionary/{dataset_name}_test_graph_motifidx_{date_tag}.pickle', 'wb') as file:\n",
    "    pickle.dump(test_graph_to_motifs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7508cf-1f0c-43f9-b7a8-914f2cabbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'dictionary/{dataset_name}_test_graph_lookup_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(test_data_lookup, file)\n",
    "    \n",
    "with open(f'dictionary/{dataset_name}_test_graph_motif_length_{date_tag}.pickle', 'wb') as file:\n",
    "    # Serialize and save the object to the file\n",
    "    pickle.dump(lookup.get_test_motif_lengths(), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032919b4-5856-4a8b-a41a-92be73882f6d",
   "metadata": {},
   "source": [
    "# Visualization of motif occurences in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b65998-fb01-4468-aef5-add41fca8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_binary_values(input_dict):\n",
    "    output_dict = {}\n",
    "    for key, graph_label in input_dict.items():\n",
    "        values = list(graph_label.values())\n",
    "        count_0 = values.count(0)\n",
    "        count_1 = values.count(1)\n",
    "        output_dict[key] = (count_0, count_1)\n",
    "    return output_dict\n",
    "\n",
    "value_counts = count_binary_values(lookup.motifs_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f24fb-7339-4f6d-8257-7001cf876027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = lookup.motifs_length\n",
    "counter = value_counts\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = []\n",
    "classes = [0, 1]\n",
    "for key, length in data.items():\n",
    "    counts = counter[key]\n",
    "    for cls in classes:\n",
    "        df.append((key, length, cls, counts[cls]))\n",
    "df = pd.DataFrame(df, columns=['Key', 'Length', 'Class', 'Count'])\n",
    "\n",
    "# Sort DataFrame by Length in descending order\n",
    "df = df.sort_values(by='Length', ascending=False)\n",
    "\n",
    "# Create a mapping of motifs to unique integer values\n",
    "motif_mapping = {motif: i for i, motif in enumerate(df['Key'].unique())}\n",
    "\n",
    "# Create a new column for mapped motif numbers using .map\n",
    "df.loc[:, 'Key_Num'] = df['Key'].map(motif_mapping)\n",
    "\n",
    "# Split the data into two separate DataFrames for each class\n",
    "df_class_0 = df[df['Class'] == 0].copy()\n",
    "df_class_1 = df[df['Class'] == 1].copy()\n",
    "\n",
    "# Calculate the absolute difference in counts between Class 0 and Class 1 for each motif\n",
    "df_counts = df.pivot(index='Key', columns='Class', values='Count').fillna(0)\n",
    "df_counts['Difference'] = abs(df_counts[0] - df_counts[1])\n",
    "\n",
    "# Set a threshold for significant difference\n",
    "significant_threshold = 100  # Example threshold, adjust as needed\n",
    "significant_motifs = df_counts[df_counts['Difference'] > significant_threshold].index\n",
    "\n",
    "# Separate significant and non-significant motifs\n",
    "df_significant = df[df['Key'].isin(significant_motifs)].copy()\n",
    "df_non_significant = df[~df['Key'].isin(significant_motifs)].copy()\n",
    "\n",
    "# Plot significant motifs\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "for cls in classes:\n",
    "    subset = df_significant[df_significant['Class'] == cls]\n",
    "    ax.bar(subset['Key_Num'] + cls * 0.4, subset['Count'], width=0.4, label=f'Class {cls}', alpha=0.7)\n",
    "\n",
    "ax.set_title('Counts of Significant Motifs')\n",
    "ax.set_xlabel('Motifs')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([motif_mapping[motif] + 0.2 for motif in significant_motifs])\n",
    "ax.set_xticklabels(significant_motifs, rotation=45)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot non-significant motifs in groups of 100\n",
    "non_sig_motifs = df_non_significant['Key'].unique()\n",
    "num_groups = int(np.ceil(len(non_sig_motifs) / 100))\n",
    "\n",
    "for i in range(num_groups):\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    \n",
    "    start = i * 100\n",
    "    end = (i + 1) * 100\n",
    "    current_motifs = non_sig_motifs[start:end]\n",
    "    df_current = df_non_significant[df_non_significant['Key'].isin(current_motifs)].copy()\n",
    "    \n",
    "    for cls in classes:\n",
    "        subset = df_current[df_current['Class'] == cls]\n",
    "        ax.bar(subset['Key_Num'] + cls * 0.4, subset['Count'], width=0.4, label=f'Class {cls}', alpha=0.7)\n",
    "\n",
    "    ax.set_title(f'Counts of Non-Significant Motifs (Group {i + 1}/{num_groups})')\n",
    "    ax.set_xlabel('Motifs')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_xticks([motif_mapping[motif] + 0.2 for motif in current_motifs])\n",
    "    ax.set_xticklabels(current_motifs, rotation=90)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3e2c9-9602-4754-9b80-8349c6b903b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Key', y='Count', hue='Class', data=df_significant)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Motif')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts of Significant Motifs by Class')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-ticks for better readability\n",
    "\n",
    "# Display the plot\n",
    "plt.legend(title='Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f209e55-c7a6-4c3f-bdf1-90ec0f62e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Key'] == '*ON(*)O*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc7f19a8-f9b7-4d3a-b15d-2afcfcf07a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Length</th>\n",
       "      <th>Class</th>\n",
       "      <th>Count</th>\n",
       "      <th>Key_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>*[N+](=O)[O-]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>*[N+](=O)[O-]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Key  Length  Class  Count  Key_Num\n",
       "266  *[N+](=O)[O-]       3      0     26      247\n",
       "267  *[N+](=O)[O-]       3      1     46      247"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Key'] == '*[N+](=O)[O-]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53032fa2-47ee-46f5-97f2-48996c7675e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Length</th>\n",
       "      <th>Class</th>\n",
       "      <th>Count</th>\n",
       "      <th>Key_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Key, Length, Class, Count, Key_Num]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Key'] == '*[NH+]([O-])O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bbdca6d-9c6e-430e-9ae4-7cf6a03bccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Length</th>\n",
       "      <th>Class</th>\n",
       "      <th>Count</th>\n",
       "      <th>Key_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>*c1c(F)cnc2ccc(=O)n(*)c12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>*c1c(F)cnc2ccc(=O)n(*)c12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>*c1cc(=O)c2ccc(F)cc2o1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>*c1cc(=O)c2ccc(F)cc2o1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>*N1CCC2(CC1)C(=O)N(*)C(=O)N2*</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>*C(*)(*)*</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>*O*</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1328</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>*O*</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1384</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>*N*</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1813</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*N*</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2045</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Key  Length  Class  Count  Key_Num\n",
       "271      *c1c(F)cnc2ccc(=O)n(*)c12      12      1     11        0\n",
       "270      *c1c(F)cnc2ccc(=O)n(*)c12      12      0     34        0\n",
       "389         *c1cc(=O)c2ccc(F)cc2o1      12      1     26        1\n",
       "388         *c1cc(=O)c2ccc(F)cc2o1      12      0     27        1\n",
       "249  *N1CCC2(CC1)C(=O)N(*)C(=O)N2*      12      1     20        2\n",
       "..                             ...     ...    ...    ...      ...\n",
       "257                      *C(*)(*)*       1      1    194      305\n",
       "14                             *O*       1      0   1328      306\n",
       "15                             *O*       1      1   1384      306\n",
       "5                              *N*       1      1   1813      307\n",
       "4                              *N*       1      0   2045      307\n",
       "\n",
       "[616 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bafeb53-f93b-4863-a96a-d82a20842c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*1N1O2'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_counts('*[N+](=O)[O-]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e065b88-fb03-4bed-8f80-e1ee6bd27e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*3N1O2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_counts('*ON(*)O*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef807e4-0d7e-444d-989d-a3fdbab966d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b8d24-6758-4ac6-bac8-6ebbb5b86192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ea9eb-92a9-4828-bc62-4b68fa4859f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
